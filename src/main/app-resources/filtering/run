#!/opt/anaconda/envs/env_ewf_wfp_03_01_03/bin/python
##########
# This node recieves pandas dataframe of  tile time-series in pickle format 
# each tile containing 6 bands: 'NDVI', 'OGVI', 'OTCI', 'Land mask', 'Cloud mask', 'OGVI fail mask' 
# Smooth & gap-filters each subtile for NDVI, OGVI or OTCI based on the name of the pickle  
# Saves the output NDVI, OGVI or OTCI interpolated results + Original Data + Mask   
# Note! input noData value is 255. 
#########
import os
import sys
import string
import atexit
import numpy as np
import pandas as pd
sys.path.append('/'.join([os.environ['_CIOP_APPLICATION_PATH'], 'util']))
sys.path.append('../util')
from s3_whittaker_helpers import *
import cioppy 
ciop = cioppy.Cioppy()
    
# define the exit codes
SUCCESS = 0
ERR_RESOLUTION = 10
ERR_STAGEIN = 20
ERR_NO_OUTPUT = 30

# add a trap to exit gracefully
def clean_exit(exit_code):
    log_level = 'INFO'
    if exit_code != SUCCESS:
        log_level = 'ERROR'  
   
    msg = {SUCCESS: 'Processing successfully concluded',
           ERR_RESOLUTION: 'Could not resolve Sentinel-1 product enclosure',
           ERR_STAGEIN: 'Could not stage-in Sentinel-1 product', 
           ERR_NO_OUTPUT: "Missing output"
    }
 
    ciop.log(log_level, msg[exit_code])  

def main():
        
    ciop = cioppy.Cioppy()
    
    os.chdir(ciop.tmp_dir)
    delta_day = int(ciop.getparam('delta_day'))

    data_pipeline_parameters = dict()    
    data_pipeline_parameters['username'] = ciop.getparam('_T2Username')
    data_pipeline_parameters['api_key'] = ciop.getparam('_T2ApiKey')
    
    #Open each pickle and process the time-series 
    for input in sys.stdin:
        tile_pkl = ciop.copy(input.rstrip(),ciop.tmp_dir,extract=False)
        tile_series = pd.read_pickle(tile_pkl, 'gzip')
        
        tile_name = os.path.basename(tile_pkl).split('.')[0]
        ciop.log('DEBUG', 'Processing local tile {}'.format(tile_name))
        
        #Name of the pickle determines the band ie. NDVI ,OGVI ot OTCI
        band_to_process = tile_name[-4:]
        ciop.log('DEBUG','band to process is : {}'.format(band_to_process))
        
        dates = tile_series['jday']
        
        # the generate_dates function creates a list of days with a delta time=1
        full_dates = generate_dates(startdate_string=list(dates)[0], enddate_string=list(dates)[-1], delta=1)
        # Parameter to be set in metadata 
        full_period = '{}_{}'.format(fromjulian(full_dates[0]).strftime('%Y%m%d'),fromjulian(full_dates[-1]).strftime('%Y%m%d'))
        date_mask = np.array([True if x in list(dates) else False for x in full_dates])
        
        ciop.log('DEBUG','full dates = {0} while original input dates = {1}'.format(len(full_dates), len(dates)))
        ciop.log('DEBUG','full period of processing is : {}'.format(full_period))
        
        #########Read input data & stack them into a 3D array
        ####Find out bands description:
        temp_des = gdal.Open(get_vsi_url(tile_series.iloc[0]['enclosure'], 
                                    data_pipeline_parameters['username'], 
                                    data_pipeline_parameters['api_key']))
        bands = dict()
        for band in range(temp_des.RasterCount):
            band += 1
            bands[temp_des.GetRasterBand(band).GetDescription()] = band 
        
        
        geo_transform = temp_des.GetGeoTransform()
        projection = temp_des.GetProjection()
        
        temp_des = None

        ciop.log('DEBUG','bands : {}'.format(bands))
        
        
        #### Find upperLeft & lowerRight GPS coordinates for each input entry
        tile_series = tile_series.merge(tile_series.apply(lambda row: analyse_gps(row,data_pipeline_parameters['username'], 
                                    data_pipeline_parameters['api_key']), axis=1),
                                                        left_index=True,
                                                        right_index=True)
        
        #### Check if all tiles have same geometry 
        

        if (tile_series['ul_x'].nunique() >1 or 
            tile_series['ul_y'].nunique() >1 or 
            tile_series['lr_x'].nunique() >1 or 
            tile_series['lr_y'].nunique() >1) :
            ciop.log('DEBUG','Tile series mismatch in geometry! Process fails!')  
            
            

        
        
        #### Read the data & create the mask
 
        data = []
        mask = []
        for index, row in tile_series.iterrows():
            
            enclosure_vsi_url = get_vsi_url(row.enclosure, 
                                    data_pipeline_parameters['username'], 
                                    data_pipeline_parameters['api_key'])
            src_ds = gdal.Open(enclosure_vsi_url)
            data.append(src_ds.GetRasterBand(bands[band_to_process]).ReadAsArray())
    
            land_mask = src_ds.GetRasterBand(bands['Land mask']).ReadAsArray()
            cloud_mask = src_ds.GetRasterBand(bands['Cloud mask']).ReadAsArray()
            #noData 255
            mask.append( (land_mask==1) & (cloud_mask==0) ) # if mask is true data is valid


            
            
        data_stack = np.stack(data,axis=0)
        validity_mask_stack = np.stack(mask,axis=0)
        ciop.log('DEBUG','Complete data stack shape = {}'.format(data_stack.shape))
        
        #########Run Whittaker filter 
        
        result = np.apply_along_axis(whittaker, 0, data_stack,date_mask)
        ciop.log('DEBUG','result.shape = {}'.format(result.shape))
        
        
        
        
        #########Save filtered result to seperate GeoTiff file per delta_day 
        ###Five types of output GeoTiff generated: Sgrid , Lag1 , ORI data , MASK & SYS|NAT data  
        
        ###Creating Sgrid GeoTiff
        
        ciop.log('INFO', 'Create s-grid GeoTIFF product for local tile {}'.format(tile_name))

        band_number = 1
        cols = result.shape[1]
        rows = result.shape[2]

        print('S-grid', band_number, cols, rows)

        drv = gdal.GetDriverByName('GTiff')

        ds = drv.Create('tmp_sgrid.tif', 
                        cols, rows, 
                        band_number, 
                        gdal.GDT_Int16)

        log10_scale100 = lambda x: 0 if np.isnan(x) else(0 if x<=0 else 100*np.log10(x))
        vfunc_log_scale100 = np.vectorize(log10_scale100)
        S_grid = vfunc_log_scale100(result[0])
        
        ds.SetGeoTransform(geo_transform)
        ds.SetProjection(projection)
        ds.GetRasterBand(1).WriteArray(S_grid, 0, 0)
        ds.GetRasterBand(1).SetDescription('Sgrid')
        
        ### Metadata for Sgrid
        metadata = dict()
        metadata['full_period'] = full_period
        ds.GetRasterBand(1).SetMetadata(metadata)
        
        translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co TILED=YES ' \
                                                                        '-co COPY_SRC_OVERVIEWS=YES ' \
                                                                        '-co COMPRESS=LZW '\
                                                                        '-a_nodata 0'))
        gdal.SetConfigOption('COMPRESS_OVERVIEW', 'DEFLATE')
        ds.BuildOverviews('NEAREST', [2,4,8,16,32])
        gdal.Translate('sgrid_{}_{}.tif'.format(band_to_process, tile_name), ds,  options=translate_options)
        
        
        
        ds.FlushCache()

        ciop.publish(os.path.join(ciop.tmp_dir, 'sgrid_{}_{}.tif'.format(band_to_process, tile_name)), metalink=True)
        
        
        ### Creating the lag1corr GeoTiff
        
        ciop.log('INFO', 'Create the Lag-1 GeoTIFF product for local tile {}'.format(tile_name))

        band_number = 1
        cols = result.shape[1]
        rows = result.shape[2]

        print('Lag-1', band_number, cols, rows)
        drv = gdal.GetDriverByName('GTiff')

        ds = drv.Create('temp_lag1.tif'.format(band_to_process,tile_name), 
                        cols, rows, 
                        band_number, 
                        gdal.GDT_Int16)

        lag1_scale100 = lambda x: 255 if np.isnan(x) or np.isinf(x) or x==255  else x*100
        vfunc_lag1_scale100 = np.vectorize(lag1_scale100)
       
        
        
        ds.SetGeoTransform(geo_transform)
        ds.SetProjection(projection)
        ds.GetRasterBand(1).WriteArray(vfunc_lag1_scale100(result[1]), 0, 0)
        ds.GetRasterBand(1).SetDescription('lag1')
        
        ###Metadata for lag1 
        metadata = dict()
        metadata['full_period'] = full_period
        ds.GetRasterBand(1).SetMetadata(metadata)
        
        translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co TILED=YES ' \
                                                                        '-co COPY_SRC_OVERVIEWS=YES ' \
                                                                        '-co COMPRESS=LZW '\
                                                                        '-a_nodata 255'))
        gdal.SetConfigOption('COMPRESS_OVERVIEW', 'DEFLATE')
        ds.BuildOverviews('NEAREST', [2,4,8,16,32])
        gdal.Translate('lag1_{}_{}.tif'.format(band_to_process, tile_name),ds,options=translate_options)
        
        
        ds.FlushCache()

        ciop.publish(os.path.join(ciop.tmp_dir, 'lag1_{}_{}.tif'.format(band_to_process,tile_name)), metalink=True)
        
        
        
        ### Creating original values GeoTiff ###
        
        ciop.log('INFO', 'Create the original {} GeoTIFF product for local tile {}'.format(band_to_process, tile_name))
        band_number = data_stack.shape[0]
        cols = data_stack.shape[1]
        rows = data_stack.shape[2]

        ciop.log('DEBUG', ' '.join(['original values', str(band_number), str(cols), str(rows)]))

        drv = gdal.GetDriverByName('GTiff')

        ds = drv.Create('temp_originals.tif',
                        cols, rows, 
                        band_number, 
                        gdal.GDT_Int16)

        ds.SetGeoTransform(geo_transform)
        ds.SetProjection(projection)
        ds.FlushCache()
        
        ds = gdal.Open('temp_originals.tif', gdal.OF_UPDATE)
        
        
        scale10k = lambda x: -20000 if x==255 else x*10000
        vfunc_scale = np.vectorize(scale10k,otypes=[np.int16])

        
        for index, band in enumerate(range(0, band_number)):

            
            product_date = datetime.datetime.strptime(dates[index], '%Y%j').date()
            date = '{}{:02d}{:02d}'.format(product_date.year, product_date.month, product_date.day)
            
            metadata = dict()
            metadata['date'] = date
            metadata['jdate'] = dates[index]
            metadata['full_period'] = full_period
            
            #ORIGINAL band
            
            ds.GetRasterBand(index + 1).WriteArray(vfunc_scale(data_stack[index]), 0, 0)
            ds.GetRasterBand(index + 1).SetDescription('ORI {}'.format(date))
            ds.GetRasterBand(index + 1).SetMetadata(metadata)

            
            
            
        translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co TILED=YES ' \
                                                                        '-co COPY_SRC_OVERVIEWS=YES ' \
                                                                        '-co COMPRESS=LZW '\
                                                                        '-a_nodata -20000'))
        gdal.SetConfigOption('COMPRESS_OVERVIEW', 'DEFLATE')
        ds.BuildOverviews('NEAREST', [2,4,8,16,32])
        
        gdal.Translate('originals_{}_{}.tif'.format(band_to_process, tile_name),ds,options=translate_options)
        ds.FlushCache()
        
        
        ciop.publish(os.path.join(ciop.tmp_dir, 'originals_{}_{}.tif'.format(band_to_process, tile_name)), metalink=True)
        
                     
        ### Creating mask values GeoTiff ###
        
        ciop.log('INFO', 'Create the mask {} GeoTIFF product for local tile {}'.format(band_to_process, tile_name))
        band_number = validity_mask_stack.shape[0]
        cols = validity_mask_stack.shape[1]
        rows = validity_mask_stack.shape[2]

        ciop.log('DEBUG', ' '.join(['mask values', str(band_number), str(cols), str(rows)]))

        drv = gdal.GetDriverByName('GTiff')

        ds = drv.Create('temp_mask.tif',
                        cols, rows, 
                        band_number, 
                        gdal.GDT_Int16)

        ds.SetGeoTransform(geo_transform)
        ds.SetProjection(projection)
        ds.FlushCache()
        
        ds = gdal.Open('temp_mask.tif', gdal.OF_UPDATE)

        for index, band in enumerate(range(0, band_number)):
        
            product_date = datetime.datetime.strptime(dates[index], '%Y%j').date()
            date = '{}{:02d}{:02d}'.format(product_date.year, product_date.month, product_date.day)
            
            metadata = dict()
            metadata['date'] = date
            metadata['jdate'] = dates[index]
            metadata['full_period'] = full_period

            ds.GetRasterBand(index + 1).WriteArray(validity_mask_stack[index], 0, 0)
            ds.GetRasterBand(index + 1).SetDescription('Mask {}'.format(date))
            ds.GetRasterBand(index + 1).SetMetadata(metadata)
        
        
        
        translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co TILED=YES ' \
                                                                        '-co COPY_SRC_OVERVIEWS=YES ' \
                                                                        '-co COMPRESS=LZW '\
                                                                        '-a_nodata 255'))
        gdal.SetConfigOption('COMPRESS_OVERVIEW', 'DEFLATE')
        ds.BuildOverviews('NEAREST', [2,4,8,16,32])
        gdal.Translate('masks_{}_{}.tif'.format(band_to_process, tile_name),ds,options=translate_options)
        ds.FlushCache()
        
        
        
        ciop.publish(os.path.join(ciop.tmp_dir, 'masks_{}_{}.tif'.format(band_to_process, tile_name)), metalink=True)
        
        
        
        ### Creating Interpolated data GeoTiff ###
        
        ciop.log('INFO', 'Create the {} GeoTIFF product for local tile {}'.format(band_to_process, tile_name))
        
        out_bands = range(0, result.shape[0]-2, delta_day)
        
        band_number = len(out_bands)
        cols = result.shape[1]
        rows = result.shape[2]

        ciop.log('DEBUG', ' '.join([str(band), str(band_number), str(cols), str(rows)]))

        drv = gdal.GetDriverByName('GTiff')

        ds = drv.Create('temp_{}.tif'.format(band_to_process), 
                        cols, rows, 
                        band_number, 
                        gdal.GDT_Int16)

        ds.SetGeoTransform(geo_transform)
        ds.SetProjection(projection)
        ds.FlushCache()
        
        ds = gdal.Open('temp_{}.tif'.format(band_to_process), gdal.OF_UPDATE)

        delta_day_index=0
        
        scale10k_conditioned = lambda x: -20000 if np.isnan(x) or np.isinf(x) or x==255 else x*10000
        vfunc_scale_con = np.vectorize(scale10k_conditioned)
                

        
        for index in out_bands:
            
            ciop.log('DEBUG', '{} initial number of bands: {}'.format(band_to_process,ds.RasterCount))
            
            ciop.log('DEBUG', 'index : {}'.format(index))
            
            product_date = datetime.datetime.strptime(full_dates[index], '%Y%j').date()
            date = '{}{:02d}{:02d}'.format(product_date.year, product_date.month, product_date.day)
            band_is_interpolated = 'False' if full_dates[index] in list(dates) else 'True'
            

            metadata = dict()
            metadata['date'] = date
            metadata['jdate'] = full_dates[index]
            metadata['band_is_interpolated'] = band_is_interpolated
            metadata['full_period'] = full_period
            delta_day_index += 1
            
            ciop.log('DEBUG', 'band index {}'.format(delta_day_index))
            
            ### NAT & SYN bands 

            ds.GetRasterBand(delta_day_index).WriteArray(vfunc_scale_con(result[index + 2]), 0, 0)
            if band_is_interpolated=='True':
                ds.GetRasterBand(delta_day_index).SetDescription('SYN {}'.format(date))
            else:
                ds.GetRasterBand(delta_day_index).SetDescription('NAT {}'.format(date))
            ds.GetRasterBand(delta_day_index).SetMetadata(metadata)
        
        ciop.log('DEBUG', '{} number of bands: {}'.format(band_to_process,ds.RasterCount))
        
        
        
        translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co TILED=YES ' \
                                                                        '-co COPY_SRC_OVERVIEWS=YES ' \
                                                                        '-co COMPRESS=LZW '\
                                                                        '-a_nodata -20000'))
        gdal.SetConfigOption('COMPRESS_OVERVIEW', 'DEFLATE')
        ds.BuildOverviews('NEAREST', [2,4,8,16,32])
        gdal.Translate('{}_{}.tif'.format(band_to_process, tile_name),
                   ds, 
                   options=translate_options)
        ds.FlushCache()

        ciop.publish(os.path.join(ciop.tmp_dir, '{}_{}.tif'.format(band_to_process, tile_name)), metalink=True)
        

      
        

try:
    main()
except SystemExit as e:
    if e.args[0]:
        clean_exit(e.args[0])
    raise
else:
    atexit.register(clean_exit, 0)
