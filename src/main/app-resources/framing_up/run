#!/opt/anaconda/envs/env_ewf_wfp_03_01_03/bin/python
#########
## This node recieves a comma seperated list of input references - various tiles 
## GDAL opens and get the GeoTransform data per tile
## Groups tiles according to geometry and sort by date 
## publishes each group as a pickle file containing panda DataFrame 
#########
import os
import sys
import string
import atexit
import gdal

import cioppy 
ciop = cioppy.Cioppy()
import pandas as pd
sys.path.append('/'.join([os.environ['_CIOP_APPLICATION_PATH'], 'util']))
sys.path.append('../util')
from s3_whittaker_helpers import *
# define the exit codes
SUCCESS = 0
ERR_RESOLUTION = 10
ERR_STAGEIN = 20
ERR_NO_OUTPUT = 30

# add a trap to exit gracefully
def clean_exit(exit_code):
    log_level = 'INFO'
    if exit_code != SUCCESS:
        log_level = 'ERROR'  
   
    msg = {SUCCESS: 'Processing successfully concluded',
           ERR_RESOLUTION: 'Could not resolve Sentinel-1 product enclosure',
           ERR_STAGEIN: 'Could not stage-in Sentinel-1 product', 
           ERR_NO_OUTPUT: "Missing output"
    }
 
    ciop.log(log_level, msg[exit_code])  

def main():
    ciop = cioppy.Cioppy()
    
    data_pipeline_parameters = dict()    
    
    data_pipeline_parameters['username'] = ciop.getparam('_T2Username')
    data_pipeline_parameters['api_key'] = ciop.getparam('_T2ApiKey')
    


    os.chdir(ciop.tmp_dir)
    ### Temporary value for test
    path_to_store='https://store.terradue.com/ppishehvar/_results/workflows/ec_better_ewf_wfp_03_01_01_ewf_wfp_03_01_01_0_2/run/1e631064-b158-11ea-bbe6-0242ac110003/0013082-200518181542206-oozie-oozi-W/9a2364b0-51ef-4a2b-a397-a0e0c28459aa/'
    
    
    
    references = []
        
    for input in sys.stdin:
        ciop.log('INFO', 'Adding {}'.format(input.rstrip()))       
        references.append(input.rstrip().split(',')[0])
        
#To be modified when input data pipeline is configured        
    data_pipeline_results = pd.DataFrame()
    input_tile=dict()
    for end_point in references:
        ciop.log('INFO', 'Getting metadata for {}'.format(end_point)) 
        input_tile['tile'] = end_point
        input_tile['title'] = end_point.split('.')[0]
        input_tile['enclosure'] = '{}/{}'.format(path_to_store,end_point)
        vsi_ds=get_vsi_url(input_tile['enclosure'],data_pipeline_parameters['username'],data_pipeline_parameters['api_key'])
        ds=gdal.Open(vsi_ds)
        gt = ds.GetGeoTransform()
        input_tile['upper_left']=gdal.ApplyGeoTransform(gt,0,0)
        input_tile['lower_right']=gdal.ApplyGeoTransform(gt,ds.RasterXSize,ds.RasterYSize)
        data_pipeline_results=data_pipeline_results.append(input_tile, ignore_index=True)
       
    data_pipeline_results = data_pipeline_results.merge(data_pipeline_results.apply(lambda row: analyse_row(row), axis=1),
                                                        left_index=True,
                                                        right_index=True)




### Convert gps coordinates into comma seprated string to be inter-comparable 
    data_pipeline_results['Upper_Left']=[','.join(map(str, l)) for l in data_pipeline_results['upper_left']]
    data_pipeline_results['lower_right']=[','.join(map(str, l)) for l in data_pipeline_results['lower_right']]
    origin_points = data_pipeline_results['upper_left'].unique().tolist()

### Group tiles by geometry and sort by date
    for origin in origin_points:
        tile_stack=data_pipeline_results[data_pipeline_results['upper_left'] == origin].reset_index(drop=True)
        if tile_stack['lower_right'].unique():
            tile_stack.sort_values(by=['jday'],inplace=True, ignore_index=True)
            tile_stack_name=tile_stack.iloc[0]['title']
            tile_stack.to_pickle(os.path.join(ciop.tmp_dir,'{}.pickle'.format(tile_stack_name)), 'gzip')
            ciop.log('INFO', 'Publish {}.pickle'.format(tile_stack_name))
            ciop.publish(os.path.join(ciop.tmp_dir, '{}.pickle'.format(tile_stack_name)))
    




try:
    main()
except SystemExit as e:
    if e.args[0]:
        clean_exit(e.args[0])
    raise
else:
    atexit.register(clean_exit, 0)
