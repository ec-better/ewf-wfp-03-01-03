#!/opt/anaconda/envs/env_ewf_wfp_03_01_03/bin/python
#########
## This node recieves a comma seperated list of input references 
## GDAL opens and does tiling 
## Saves tiles in pickle format
#########
import os
import sys
import string
import atexit

import cioppy 
ciop = cioppy.Cioppy()
import pandas as pd
sys.path.append('/'.join([os.environ['_CIOP_APPLICATION_PATH'], 'util']))
sys.path.append('../util')
from s3_whittaker_helpers import *
# define the exit codes
SUCCESS = 0
ERR_RESOLUTION = 10
ERR_STAGEIN = 20
ERR_NO_OUTPUT = 30

# add a trap to exit gracefully
def clean_exit(exit_code):
    log_level = 'INFO'
    if exit_code != SUCCESS:
        log_level = 'ERROR'  
   
    msg = {SUCCESS: 'Processing successfully concluded',
           ERR_RESOLUTION: 'Could not resolve Sentinel-1 product enclosure',
           ERR_STAGEIN: 'Could not stage-in Sentinel-1 product', 
           ERR_NO_OUTPUT: "Missing output"
    }
 
    ciop.log(log_level, msg[exit_code])  

def main():
    ciop = cioppy.Cioppy()
    
    data_pipeline_parameters = dict()    
    
    data_pipeline_parameters['username'] = ciop.getparam('_T2Username')
    data_pipeline_parameters['api_key'] = ciop.getparam('_T2ApiKey')
    
    creds = '{}:{}'.format(data_pipeline_parameters['username'],
                           data_pipeline_parameters['api_key'])

    os.chdir(ciop.tmp_dir)
 
    references = []
        
    for input in sys.stdin:
        ciop.log('INFO', 'Adding {}'.format(input.rstrip()))       
        references.append(input.rstrip().split(',')[0])
        
#To be modified when input data pipeline is configured        
    data_pipeline_results = pd.DataFrame()
    for index, end_point in enumerate(references):
        ciop.log('INFO', 'Getting metadata for {}'.format(end_point)) 


#        temp_df = pd.DataFrame.from_dict(ciop.search(end_point=end_point,
#                                                     params=[],
#                                                     output_fields='startdate,title,wkt,enddate', 
#                                                     model='EOP',
#                                                     timeout='60000',
#                                                     creds=creds))

        temp_df = pd.DataFrame({'enclosure':'{}'.format(end_point),'title':'{}'.format(end_point.split('/')[-1].split('.')[0])},index=[index])
        data_pipeline_results = data_pipeline_results.append(temp_df, ignore_index=True)        
    data_pipeline_results = data_pipeline_results.merge(data_pipeline_results.apply(lambda row: analyse_row(row), axis=1),
                                                        left_index=True,
                                                        right_index=True)




# Tiles size 1917x1917 devided by 3 generates 9 sub_tiles size 639x639
    tiling_factor = 3
    sub_tiles = get_sub_tiles(data_pipeline_results, data_pipeline_parameters, tiling_factor)
    ciop.log('INFO', 'Number of subtiles: {}'.format(len(sub_tiles)))
    
    for index, sub_tile in enumerate(sub_tiles.sub_tile.unique()):
        
        print(index,sub_tile)
    
        sub_tiles[sub_tiles['sub_tile'] == sub_tile].sort_values(by=['day']).reset_index().to_pickle(os.path.join(ciop.tmp_dir,
                                                                                                                  '{}.pickle'.format(sub_tile)), 'gzip')
        #Testing condition to reduce tiles
        #if index >= 1: continue
        
        ciop.log('INFO', 'Publish {}.pickle'.format(sub_tile))
        ciop.publish(os.path.join(ciop.tmp_dir, '{}.pickle'.format(sub_tile)))


    


try:
    main()
except SystemExit as e:
    if e.args[0]:
        clean_exit(e.args[0])
    raise
else:
    atexit.register(clean_exit, 0)
